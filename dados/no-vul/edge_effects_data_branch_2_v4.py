# -*- coding: utf-8 -*-
"""edge-effects-data-branch-2-v4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13W0OYddHdY5RGrOsXNuGKGS5J7CY1FKT

## Downloads
"""

#!pip install osmnx

"""## Imports"""

import osmnx as ox
import plotly.express as px
import networkx as nx
import numpy as np
import pandas as pd
from shapely.constructive import normalize
import requests
from io import StringIO
import matplotlib.pyplot as plt
import matplotlib as mpl
import time as t
import ast
import math
import plotly.graph_objects as go
from sklearn.metrics import mean_squared_error
import matplotlib.lines as mlines

"""## Constants"""

# certo

CITY_SP = 'São Paulo'
UF_SP = 'sp'
CENTER_POINT_SP = -23.546, -46.634

CITY_SJ = 'São José dos Campos'
UF_SJ = 'sj'
CENTER_POINT_SJ = -23.220,-45.891

CITY_RJ =  'Rio de Janeiro'
UF_RJ = 'rj'
CENTER_POINT_RJ = -22.909,-43.184

CITY_BA =  'Barcelona'
UF_BA = 'ba'
CENTER_POINT_BA = 41.390, 2.166

CITY_MA =  'Manhattan'
UF_MA = 'ma'
CENTER_POINT_MA = 40.748, -73.985

CITY_BR = 'Brasília'
UF_BR = 'br'
CENTER_POINT_BR = -15.796,-47.891


MAX_RADIUS = 3100
RADIUS_SUBGRAPH = 3000
INCREMENTS = 2
MEASURES_TIME = 10

SIGLA = 'bc'

# MEASURE = 'Grau'
# SIGLA = 'dc'

G_SP = ox.graph_from_point(CENTER_POINT_SP, dist = RADIUS_SUBGRAPH, dist_type='bbox', network_type='drive', truncate_by_edge=True)
G_SJ = ox.graph_from_point(CENTER_POINT_SJ, dist = RADIUS_SUBGRAPH, dist_type='bbox', network_type='drive', truncate_by_edge=True)
G_RJ = ox.graph_from_point(CENTER_POINT_RJ, dist = RADIUS_SUBGRAPH, dist_type='bbox', network_type='drive', truncate_by_edge=True)
G_BA = ox.graph_from_point(CENTER_POINT_BA, dist = RADIUS_SUBGRAPH, dist_type='bbox', network_type='drive', truncate_by_edge=True)
G_MA = ox.graph_from_point(CENTER_POINT_MA, dist = RADIUS_SUBGRAPH, dist_type='bbox', network_type='drive', truncate_by_edge=True)
G_BR = ox.graph_from_point(CENTER_POINT_BR, dist = RADIUS_SUBGRAPH, dist_type='bbox', network_type='drive', truncate_by_edge=True)

SIZE_SP = len(G_SP)
SIZE_SJ = len(G_SJ)
SIZE_RJ = len(G_RJ)
SIZE_BA = len(G_BA)
SIZE_MA = len(G_MA)
SIZE_BR = len(G_BR)

"""## Support functions

### Steps to plots data comming from github
"""

def global_efficiency_local(graph, size):
    graph_undirected = nx.to_undirected(graph)
    n = size # len(graph)
    denom = n * (n - 1)
    if denom != 0:
        lengths = nx.all_pairs_shortest_path_length(graph_undirected)
        g_eff = 0
        for source, targets in lengths:
            for target, distance in targets.items():
                if distance > 0:
                    g_eff += 1 / distance
        g_eff /= denom
    else:
        g_eff = 0
    return g_eff

"""The point-wise vulnerability [2] :

\begin{equation}
    V(i) = \frac{E(G) - E(G, i)}{E(G)}
\end{equation}

where $V(i)$ is the point-wise vulnerability of the node $i$, $E(G)$ is the global efficiency of the network, and $E(G,i)$ is the global efficiency of a new similar network, being the only diffrence is the node $i$ disconnection from the network.
"""

def vulnerability_node(graph):

    vul = {}
    eff_before = global_efficiency_local(graph)

    for node in graph.nodes:

        # Remotion
        graph2 = graph.copy()

        for neighbor in list(graph2.neighbors(node)):
            graph2.remove_edge(node, neighbor)

        # getting efficency
        eff_after = global_efficiency_local(graph2)

        vul[node] = (eff_before - eff_after)/eff_before


    graph.graph['vulnerability-node']= vul

import functools

import networkx as nx
from networkx.exception import NetworkXError
from networkx.utils.decorators import not_implemented_for

__all__ = ["closeness_centrality", "incremental_closeness_centrality"]


def closeness_local(graph, size, u=None, distance=None, wf_improved=True):
    if graph.is_directed():
        graph = graph.reverse()  # create a reversed graph view

    if distance is not None:
        # use Dijkstra's algorithm with specified attribute as edge weight
        path_length = functools.partial(
            nx.single_source_dijkstra_path_length, weight=distance
        )
    else:
        path_length = nx.single_source_shortest_path_length

    if u is None:
        nodes = graph.nodes
    else:
        nodes = [u]
    closeness_dict = {}
    for n in nodes:
        # encontrando o comprimento do menor caminho do nó n refernte a todos os outros nos da rede
        sp = path_length(graph, n)
        totsp = sum(sp.values())
        len_G = size
        _closeness_centrality = 0.0
        if totsp > 0.0 and len_G > 1:
            _closeness_centrality = 1/totsp
            # _closeness_centrality = (len(sp) - 1.0) / totsp
            # # normalize to number of nodes-1 in connected part
            # if wf_improved:
            #     s = (len(sp) - 1.0) / (len_G - 1)
            #     _closeness_centrality *= s
        closeness_dict[n] = _closeness_centrality
    if u is not None:
        return closeness_dict[u]
    return closeness_dict

def degree_local(graph):
    if len(graph) <= 1:
        return {n: 1 for n in graph}

    centrality = {n: d for n, d in graph.degree()}
    return centrality

def communicability_local(graph):

    simple_graph = nx.Graph(graph)
    t_start = t.time()
    for i in range(MEASURES_TIME):
        com = nx.communicability_exp(simple_graph)
    t_end = t.time()
    df = pd.DataFrame(com)


    # VERIFICAR SE TEM SELF LOOPS
    verify_selfloops_1 = len(list(nx.nodes_with_selfloops(simple_graph)))

    if (verify_selfloops_1 != 0):
        print('Graph with selfloops')
        if(verify_selfloops_1 != 0):
            self_loops = list(simple_graph.edges(nx.nodes_with_selfloops(simple_graph)))
            print(self_loops)
            simple_graph.remove_edges_from(self_loops)
        else:
            print('No selfloops')

    else:
        print('Graph without selfloops')


    verify_selfloops_1 = len(list(nx.nodes_with_selfloops(simple_graph)))
    print('Second verification:')
    if (verify_selfloops_1 != 0) :
        print('Graph with selfloops')
    else:
        print('Graph without selfloops')



    past_time = t_end - t_start
    return df, past_time

"""## Way 1 - Generating data"""

def generating_data(graph, size, measures_time):

    # Nodes attributes
    # calculate node degree centrality
    time_start = t.time()
    for i in range(measures_time):
        dc = degree_local(graph)
    time_end = t.time()
    nx.set_node_attributes(graph, values = dc, name="dc")
    time_code = (time_end - time_start)
    dict_time = {}
    for node in graph:
        dict_time[node] = time_code
    nx.set_node_attributes(graph, values=dict_time, name='time-dc')

    # calculate node closeness centrality
    time_start = t.time()
    for i in range(measures_time):
        cc = closeness_local(graph, size)
    time_end = t.time()
    nx.set_node_attributes(graph, values=cc, name="cc")
    time_code = (time_end - time_start)
    dict_time = {}
    for node in graph:
        dict_time[node] = time_code
    nx.set_node_attributes(graph, values=dict_time, name='time-cc')

    # # calculate node betweenness centrality
    time_start = t.time()
    for i in range(measures_time):
        bc = nx.betweenness_centrality(graph, normalized = False, endpoints=True)
    time_end = t.time()
    nx.set_node_attributes(graph, values=bc, name="bc")
    time_code = (time_end - time_start)
    dict_time = {}
    for node in graph:
        dict_time[node] = time_code
    nx.set_node_attributes(graph, values=dict_time, name='time-bc')

    # vulnerability per efficiency - node(simple graph)
    # time_start = t.time()
    # vulnerability_node(graph)
    # time_end = t.time()
    # nx.set_node_attributes(graph, values=graph.graph['vulnerability-node'], name='vul')
    # time_code = (time_end - time_start)
    # dict_time = {}
    # for node in graph:
    #     dict_time[node] = time_code
    # nx.set_node_attributes(graph, values=dict_time, name='time-vul')


    # graph attributes
    # calculate efficiency
    time_start = t.time()
    for i in range(measures_time):
        e = global_efficiency_local(graph, size)
    time_end = t.time()
    dict_eff = {}
    for node in graph:
        dict_eff[node] = e
    nx.set_node_attributes(graph, values=dict_eff, name='eff')
    time_code = (time_end - time_start)
    dict_time = {}
    for node in graph:
        dict_time[node] = time_code
    nx.set_node_attributes(graph, values=dict_time, name='time-eff')



    time_start = t.time()
    simple_graph = nx.Graph(graph)
    for i in range(measures_time):
        sub = nx.subgraph_centrality_exp(simple_graph)
    time_end = t.time()
    nx.set_node_attributes(graph, values = sub, name="sub")
    time_code = (time_end - time_start)
    dict_time = {}
    for node in graph:
        dict_time[node] = time_code
    nx.set_node_attributes(graph, values=dict_time, name='time-sub')


    return graph

# Save data for tests
def save_data(center_point, size, measures, measures_time, size_subgraph , max_radius, uf):
    interval = (max_radius - size_subgraph)//measures;
    list_dfs_com = []

    for radius in range(size_subgraph, max_radius + interval, interval):
        time_start = t.time()
        graph = ox.graph.graph_from_point(center_point, dist = radius, dist_type='bbox',\
                                          network_type='drive', truncate_by_edge=True)
        graph = generating_data(graph, size, measures_time)

        # getting communicability
        df_com, past_time = communicability_local(graph)
        list_dfs_com.append(df_com)

        time_end = t.time()
        time_code = (time_end - time_start)
        dict_past_time = {}
        dict_all_time = {}

        for node in graph:
            dict_past_time[node] = past_time
            dict_all_time[node] = time_code

        nx.set_node_attributes(graph, values=dict_all_time, name='time-all')
        nx.set_node_attributes(graph, values=dict_past_time, name='time-com')

        nodes_df, edges_df = ox.utils_graph.graph_to_gdfs(graph)

        nodes_df.to_csv(f'data-nodes-{uf}-{radius}.csv')


        print(f'radius: {radius}\tAll time: {time_code:.2}s')

    return nodes_df, list_dfs_com

# Uncomment the line below to generate your own data
#nodes_df_sp, list_dfs_com_sp = save_data(CENTER_POINT_SP, SIZE_SP, INCREMENTS-1,MEASURES_TIME, RADIUS_SUBGRAPH, MAX_RADIUS, UF_SP)
#nodes_df_sj, list_dfs_com_sj = save_data(CENTER_POINT_SJ, SIZE_SJ, INCREMENTS-1,MEASURES_TIME, RADIUS_SUBGRAPH, MAX_RADIUS, UF_SJ)
#nodes_df_rj, list_dfs_com_rj = save_data(CENTER_POINT_RJ, SIZE_RJ, INCREMENTS-1,MEASURES_TIME, RADIUS_SUBGRAPH, MAX_RADIUS, UF_RJ)
#nodes_df_ba, list_dfs_com_ba = save_data(CENTER_POINT_BA, SIZE_BA, INCREMENTS-1,MEASURES_TIME, RADIUS_SUBGRAPH, MAX_RADIUS, UF_BA)
nodes_df_ma, list_dfs_com_ma = save_data(CENTER_POINT_MA, SIZE_MA, INCREMENTS-1,MEASURES_TIME, RADIUS_SUBGRAPH, MAX_RADIUS, UF_MA)
#nodes_df_br, list_dfs_com_br = save_data(CENTER_POINT_BR, SIZE_BR, INCREMENTS-1,MEASURES_TIME, RADIUS_SUBGRAPH, MAX_RADIUS, UF_BR)
